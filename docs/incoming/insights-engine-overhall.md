# **Insights engine overhall**

# **Issue 1 ‚Äî Dedup Failure (Adverse \+ Trend)**

### **Nature**

Pure **classification-layer bug**.

The problem is that classification is direction-based, not identity-based.

Your current logic:

`if (dir === "up" && adverseEvidenceMap.has(finding)) continue;`  
`if (dir === "down" && protectiveMap.has(finding)) continue;`

This assumes:

* Up \= adverse

* Down \= protective

But biological meaning ‚â† direction.

Testis weight ‚Üì is clearly adverse.

---

## **‚úÖ Correct Model**

You need **priority-based finding ownership**, not direction filters.

### **Canonical rule:**

`One finding ‚Üí One category`  
`Priority: Adverse > Protective > Trend`

### **Suggested architecture**

Instead of filtering trends during render, build a **finding index first**:

`type FindingCategory = "adverse" | "protective" | "trend";`

`interface FindingState {`  
  `id: string;`  
  `category: FindingCategory;`  
  `sourceRules: string[];`  
`}`

Algorithm:

1. Collect all rule hits

2. Group by finding

3. Assign highest priority category

Pseudo:

`if (adverse.has(f)) {`  
  `category = "adverse";`  
`} else if (protective.has(f)) {`  
  `category = "protective";`  
`} else if (trend.has(f)) {`  
  `category = "trend";`  
`}`

Render only that.

---

### **Why this is important long-term**

If you don‚Äôt fix this structurally, you‚Äôll keep getting edge cases like:

* Trend \+ clinical signal

* Protective \+ conflicting severity rule

* Multi-sex divergence

This should be solved at the **classification aggregation layer**, not patched in UI logic.

---

# **üü† Issue 2 ‚Äî R01 vs R07 Logical Contradiction**

### **Nature**

Not a bug. It‚Äôs a **hierarchical rule collision**.

* R01 \= statistical significance

* R07 \= pattern diagnostic

They operate at different analytical layers.

The real issue:  
 You don‚Äôt have rule precedence defined.

---

## **‚úÖ Correct Model: Rule Taxonomy**

You need rule tiers:

| Tier | Type | Examples |
| ----- | ----- | ----- |
| Tier 1 | Statistical signal | R01 |
| Tier 2 | Pattern diagnostics | R07 |
| Tier 3 | Context modifiers | Sex-specific |
| Tier 4 | Narrative amplifiers | Domain flags |

Then define suppression:

`If Tier 1 fires ‚Üí suppress Tier 2 for same finding`

This prevents contradictory narratives.

---

### **Deeper Insight**

R07 is not contradictory ‚Äî it's diagnostic metadata.  
 It should enrich R01, not compete with it.

Better output:

Significant dose-dependent decrease (p=0.0105), non-monotonic pattern.

That‚Äôs coherent.

So long-term:  
 **Convert R07 from insight to modifier.**

---

# **üü° Issue 3 ‚Äî R10 Over-Sensitivity (Cohen‚Äôs d with n=1)**

This is not just a statistical issue.

It‚Äôs a credibility issue.

Cohen‚Äôs d assumes distribution variance.  
 With n=1, variance collapses ‚Üí effect explodes.

This is mathematically correct but epistemically wrong.

---

## **‚úÖ Correct Fix**

Never gate by effect size alone.

Add minimum support criteria:

`n_affected >= 2`  
`AND`  
`group_size >= threshold`

Or:

Use:

* Fisher‚Äôs exact test for incidence

* Not Cohen‚Äôs d

---

### **Better R10 Condition**

Instead of:

`abs(d) >= 2`

Use:

`abs(d) >= 2`  
`AND n_affected >= 2`  
`AND incidence >= 10%`

Or downgrade:

Large effect (d=4.0, single animal)

The key principle:

Effect size without replication \= anecdote.

---

# **üü£ Issue 4 ‚Äî ATROPHY Domain Gap**

This is where your system becomes next-level.

Your engine is purely statistical.

Regulatory tox is not.

Certain findings are:

* Sentinel findings

* Mechanistically critical

* Regulatory red flags

Even at 1/15.

---

## **‚úÖ This Requires a Clinical Weighting Layer**

Add a domain rule tier:

`interface ClinicalPriority {`  
  `finding: string;`  
  `organ: string;`  
  `severity: number;`  
  `weight: number;`  
`}`

Examples:

* Testicular atrophy ‚Üí High weight

* Neoplasia ‚Üí High weight

* Neurodegeneration ‚Üí High weight

Then classification becomes:

`if clinical_weight >= threshold:`  
    `elevate to adverse regardless of p-value`

This is not statistical inference.  
 It is regulatory knowledge encoding.

And this is where you beat competitors.

---

# **üü¢ Issue 5 ‚Äî Protective Rules Lack Context**

This is subtle and important.

R18/R19 are naive:

‚ÄúControl 10% ‚Üí Treated 0% \= protective.‚Äù

But:

* Control noise exists

* Organ context matters

* Some organs shouldn't be interpreted ‚Äúprotectively‚Äù

---

## **‚úÖ Fix Strategy**

Protective confidence \= function of:

`baseline incidence`  
`organ`  
`finding type`  
`dose-dependence`  
`biological plausibility`

Example weighting:

`confidence =`  
  `(control_incidence >= 20%)`  
  `AND (dose-dependent decrease)`  
  `AND (organ not reproductive)`

Testis small ‚Üí low confidence  
 Bone marrow vacuoles ‚Üí moderate confidence

Add a confidence badge:

* High

* Moderate

* Low

That preserves signal without misleading users.

---

# **üîµ Issue 6 ‚Äî Regex-Based Parsing**

This is the most serious architectural risk.

Right now your frontend depends on text formatting staying stable.

That is fragile by design.

---

## **‚úÖ Proper Fix**

Backend `_emit()` should return:

`{`  
  `"rule_id": "R01",`  
  `"finding": "TESTIS (WEIGHT)",`  
  `"direction": "down",`  
  `"p_value": 0.0105,`  
  `"effect_size": -1.2,`  
  `"organ_system": "Reproductive",`  
  `"severity": 3,`  
  `"output_text": "Significant dose-dependent decrease..."`  
`}`

Frontend should use:

* Structured fields for logic

* output\_text only for display

Never parse narrative text.

---

# **üéØ If I Were Architecting SEND v2 Insights**

I would separate:

### **1Ô∏è‚É£ Detection Layer (pure rules engine)**

Produces structured signals.

### **2Ô∏è‚É£ Aggregation Layer**

Resolves:

* Dedup

* Priority

* Suppression

### **3Ô∏è‚É£ Clinical Weighting Layer**

Encodes regulatory domain logic.

### **4Ô∏è‚É£ Narrative Layer**

Generates user-readable summaries.

---

# **üß† The Meta-Observation**

You are at the transition point from:

‚ÄúStatistical rule engine‚Äù

to

‚ÄúClinical decision-support engine‚Äù

That‚Äôs a big evolution.

Most competitors (including legacy tox tools) never formalize this properly.

If you implement:

* Structured rule outputs

* Priority taxonomy

* Clinical weighting

* Support-aware effect thresholds

You‚Äôll have one of the most robust SEND insight engines in the industry.

## **1\) Formal rule hierarchy spec**

### **1.1 Core concepts**

**FindingKey (canonical identity)**  
 A finding must have a stable identity across rules, text templates, and views.

Minimum:

* `domain` (e.g., BW, CL, MI, TF)

* `specimen` (e.g., TESTIS, LIVER)

* `finding` (e.g., WEIGHT, ATROPHY)

* `sex` (M/F/Combined/Unknown)

* `timepoint` (optional; e.g., terminal, day X)

Example:

`type Sex = "M" | "F" | "Both" | "Unknown";`  
`type Direction = "up" | "down" | "none";`

`interface FindingKey {`  
  `domain: string;`  
  `specimen: string;`  
  `finding: string;`  
  `sex: Sex;`  
  `timepoint?: string;`  
`}`

**Signal (raw rule output)**  
 Every rule emits a structured signal with confidence \+ evidence.

`type SignalTier =`  
  `| "Tier1_Significance"     // p-values, formal tests`  
  `| "Tier2_Effect"           // effect size, magnitude thresholds`  
  `| "Tier3_Pattern"          // monotonicity, U-shape, step inconsistency`  
  `| "Tier4_Context"          // baseline incidence, historical control, plausibility`  
  `| "Tier5_Clinical"         // sentinel finding policies, organ-specific rules`  
  `| "Tier6_Narrative";       // text-only, explanation, labeling`

`type SignalPolarity = "adverse" | "protective" | "trend" | "neutral";`

`interface Evidence {`  
  `metric: string;                 // "p_value", "cohens_d", "incidence_delta"`  
  `value: number | string;`  
  `n_control?: number;`  
  `n_treated?: number;`  
  `n_affected?: number;`  
  `direction?: Direction;`  
  `notes?: string[];`  
`}`

`interface Signal {`  
  `ruleId: string;                 // "R01"`  
  `tier: SignalTier;`  
  `polarity: SignalPolarity;`  
  `findingKey: FindingKey;`  
  `direction: Direction;`  
  `strength: number;               // 0..1 (rule-level confidence)`  
  `evidence: Evidence[];`  
  `tags?: string[];                // ["non_monotonic", "n_small", "single_animal"]`  
`}`

**Insight (final surfaced item)**  
 An insight is the resolved output after dedup \+ suppression \+ clinical weighting.

`type InsightCategory = "Adverse" | "Protective" | "Trend" | "Informational";`

`interface Insight {`  
  `findingKey: FindingKey;`  
  `category: InsightCategory;`  
  `headline: string;`  
  `detail: string[];`  
  `supportingSignals: Signal[];`  
  `confidence: "High" | "Medium" | "Low";`  
  `flags?: string[]; // ["Sentinel", "SparseData", "TemplateRisk", ...]`  
`}`

---

### **1.2 Priority & ownership (solves Issue \#1)**

**One finding ‚Üí one surfaced category** (ownership):  
 `Adverse > Protective > Trend > Informational`

Ownership is determined *after* suppression and clinical weighting.

Algorithm (high level):

1. Group signals by `FindingKey`

2. Apply **suppression rules** (below)

3. Apply **clinical weighting overrides** (Tier5)

4. Assign final category by highest-priority remaining polarity

5. Compose narrative

---

### **1.3 Suppression rules (solves Issue \#2)**

Suppression is a rule graph that prevents contradictory or redundant messaging.

**Suppression rule format**

`interface SuppressionRule {`  
  `when: {`  
    `present: { ruleIds?: string[]; tiers?: SignalTier[]; polarity?: SignalPolarity[] };`  
    `sameFinding: boolean;`  
  `};`  
  `suppress: { ruleIds?: string[]; tiers?: SignalTier[] };`  
  `reason: string;`  
`}`

**Baseline suppression set (recommended)**

1. **Significance subsumes pattern**

* If Tier1 significance exists for a finding (e.g., R01), suppress Tier3 pattern-only signals (e.g., R07) *as standalone insights*.

* Pattern can remain as a **modifier tag** on the Tier1 insight.

2. **Adverse trumps trend**

* If any adverse signal survives for a finding, suppress trend signals for that finding (but allow trend facts in the detail section).

3. **Clinical override trumps ‚Äúnormal‚Äù**

* If Tier5 clinical-sentinel triggers, suppress ‚Äúnormal/no-signal‚Äù narratives.

4. **Sparse-data dampener**

* If any signal‚Äôs evidence indicates `n_affected < min` or `group_n < min`, suppress ‚Äústrong alarm‚Äù phrasing and force confidence down.

Practical example for your R01/R07 case:

* Keep R01 surfaced.

* Convert R07 into tag: `["non_monotonic_pattern"]`

* Add to detail: ‚ÄúPattern non-monotonic across doses.‚Äù

---

### **1.4 Confidence model (internal, used by hierarchy)**

Each signal gets a `strength` (0..1). Then insight confidence is aggregated.

Suggested components:

* **Data support**: sample sizes, n\_affected

* **Statistical robustness**: p-value, multiple testing considerations (if any)

* **Replication across sex/timepoint**

* **Cross-domain corroboration** (e.g., weight decrease \+ atrophy)

Rule authors set a base strength; engine adjusts via modifiers:

* `n_affected==1` ‚Üí cap strength at 0.35

* `p<0.01` with adequate n ‚Üí bump \+0.1 (cap 1.0)

* corroboration across domains ‚Üí bump \+0.15

---

### **1.5 Output contract (solves Issue \#6)**

Backend `_emit()` must return `Signal` with structured params.  
 Frontend must never parse template strings. `output_text` becomes display-only.

---

## **2\) Automatic scoring model for insight quality**

This is for *programmatically ranking how well the implementation answers the questions*, across your whole SEND app, not just histopath.

### **2.1 What you score**

You score **each surfaced Insight**, then aggregate to:

* per FindingKey

* per domain/specimen

* per study page (Summary, By Endpoint, By Domain)

* app-wide score

### **2.2 Scoring axes**

Each axis returns 0..1.

1. **Non-duplication (ND)**

* 1.0 if finding appears in exactly one category

* 0.0 if duplicated across categories (your Issue \#1)

* Partial penalties if duplicated but one is suppressed/not surfaced

2. **Logical coherence (LC)**

* Penalize contradictory surfaced statements for same finding.

* Example: ‚Äúsignificant dose-dependent‚Äù *and* ‚Äúinconsistent dose-response‚Äù as separate insights ‚Üí strong penalty.

* If pattern is downgraded to modifier ‚Üí no penalty.

3. **Statistical validity (SV)**

* Penalize signals that violate minimum-support policies.

* Example: Cohen‚Äôs d with `n_affected=1` flagged but still surfaced as strong ‚Üí penalty.

* If surfaced with explicit qualifier \+ low confidence ‚Üí smaller penalty.

4. **Clinical relevance (CR)**

* Reward sentinel findings being elevated appropriately.

* Penalize sentinel findings labeled ‚Äúnormal‚Äù when incidence is low but clinically meaningful (Issue \#4).

* Reward corroboration: weight change \+ lesion.

5. **Context adequacy (CA)**

* Does the insight provide the minimum context?

  * direction, dose group, effect size or incidence delta

  * sample sizes (`n_control`, `n_treated`, `n_affected`)

  * p-value where applicable

* Missing key context reduces score.

6. **Actionability (AC)**

* Does it answer ‚Äúso what / what to check next?‚Äù

* Reward: links to supporting tables, recommended drill-down view, cross-domain references.

7. **Stability / template risk (TR)**

* Penalize if the insight is derived from regex-parsed text fields.

* This is a system health score: if parsing fragile, overall score decreases.

### **2.3 Scoring formulas (concrete)**

Per insight:

`interface InsightScore {`  
  `ND: number; LC: number; SV: number; CR: number; CA: number; AC: number; TR: number;`  
  `total: number;`  
`}`

Recommended weights (tunable):

* ND 0.15

* LC 0.15

* SV 0.20

* CR 0.20

* CA 0.15

* AC 0.10

* TR 0.05

Total:

`total = 0.15*ND + 0.15*LC + 0.20*SV + 0.20*CR + 0.15*CA + 0.10*AC + 0.05*TR`

#### **Concrete checks**

**ND**

* If `FindingKey` has \>1 surfaced InsightCategory ‚Üí ND=0

* Else ND=1

**LC**

* If (Tier1 significance surfaced) and (Tier3 pattern surfaced as separate insight) ‚Üí LC=0.4

* If pattern is modifier only ‚Üí LC=1

* If adverse \+ protective both surfaced ‚Üí LC=0

**SV**

* If effect-size rule surfaced AND `n_affected < 2` ‚Üí SV=0.2 (or 0.0 if unqualified)

* If p-value surfaced but no `n` context ‚Üí SV=0.6

* If multiple metrics agree and support adequate ‚Üí SV=1.0

**CR**

* If sentinel in clinical catalog (see section 3\) AND category is Adverse ‚Üí CR=1

* If sentinel AND category Trend/Normal ‚Üí CR=0.2

* If non-sentinel but high incidence/severity and flagged ‚Üí CR high

**CA**

* Required fields checklist:

  * direction ‚úî

  * dose group(s) ‚úî

  * effect metric (p or delta or d) ‚úî

  * n context ‚úî

* CA \= (\#present / \#required)

**AC**

* If insight references at least one ‚Äúnext view‚Äù target (e.g., ‚ÄúOpen TF Histopath grid filtered to Testis‚Äù) ‚Üí \+0.3

* If lists corroborating domains/findings ‚Üí \+0.3

* If suggests confirmatory check (e.g., ‚Äúreview individual animal data‚Äù) ‚Üí \+0.4

**TR**

* If insight derived from structured params ‚Üí 1

* If derived from regex text parsing ‚Üí 0.2

### **2.4 Aggregation**

Per finding:

* Use max of totals (or average) depending on whether you want ‚Äúbest representation‚Äù or ‚Äúoverall quality‚Äù.

Per study page:

* Average weighted by severity/relevance (e.g., Adverse insights weight higher).

System health dashboard:

* Show distribution: % of insights with SV \< 0.5, ND violations count, TR score.

This is the scoring model you can use to regression-test engine changes.

---

## **3\) Regulatory-aware classification schema (clinically weighted tier)**

This addresses Issues \#4 and \#5 and makes ‚Äúclinical significance‚Äù first-class.

### **3.1 Schema goals**

1. Encode **sentinel findings** and organ-system rules (reg tox reality)

2. Provide **incidence/severity thresholds** that are lower for high-risk findings

3. Produce **confidence \+ rationale**, not just a label

4. Remain explainable and configurable (no black box)

### **3.2 Clinical catalog (knowledge base)**

Represent a curated catalog (versioned).

`type ClinicalClass =`  
  `| "Sentinel"        // raise even at low incidence`  
  `| "HighConcern"`  
  `| "ModerateConcern"`  
  `| "BackgroundNoiseSensitive" // needs high baseline to call protective`  
  `| "OrganSpecific";`

`interface ClinicalRule {`  
  `id: string; // "C_TESTIS_ATROPHY_01"`  
  `appliesTo: {`  
    `organSystems?: string[];   // ["Reproductive"]`  
    `specimens?: string[];      // ["TESTIS", "EPIDIDYMIS"]`  
    `findings?: string[];       // ["ATROPHY", "DEGENERATION"]`  
    `domains?: string[];        // optional`  
    `sex?: Sex | "Any";`  
  `};`  
  `clinicalClass: ClinicalClass;`  
  `elevateTo?: "Adverse" | "Protective";`  
  `minIncidenceTreated?: number;    // e.g., 0.05 (5%)`  
  `minNaffected?: number;           // e.g., 1 for sentinel, 2 otherwise`  
  `minSeverity?: number;            // e.g., >= 2`  
  `requireCorroboration?: {`  
    `anyOf: Array<{ specimens?: string[]; findings?: string[]; domains?: string[] }>;`  
  `};`  
  `notes: string[];`  
`}`

**Examples you‚Äôd likely want immediately**

* **Reproductive atrophy** (testis/epididymis) ‚Üí Sentinel

  * `minNaffected=1`, `minSeverity>=2` (or even \>=1 depending), optional corroboration with weight decrease / related lesions

* **Neoplasia** ‚Üí Sentinel

* **Neurotox** degenerative lesions ‚Üí HighConcern

* **Bone marrow hypocellularity/fibrosis** ‚Üí HighConcern

* **Liver necrosis** ‚Üí HighConcern

This catalog becomes your ‚Äúclinical tier.‚Äù

### **3.3 Classification pipeline (combined statistical \+ clinical)**

For each `FindingKey`, compute:

**A) Statistical signals** (Tier1-3)

* significance, effect, pattern

**B) Clinical signals** (Tier5)

* run clinical rules on incidence/severity/corroboration

* output a Tier5 Signal if triggered

**C) Fusion logic**

1. If Tier5 says `elevateTo: Adverse` ‚Üí final category Adverse (unless there is a stronger contraindication rule, rare)

2. Else if strong statistical adverse ‚Üí Adverse

3. Else if protective and context says plausible ‚Üí Protective

4. Else trend/informational

### **3.4 Protective plausibility (fixes Issue \#5)**

Add a ‚Äúprotective plausibility‚Äù gate.

Protective should require:

* baseline incidence above threshold (e.g., control incidence ‚â• 20% OR historical-control support)

* biologically plausible organ/finding class (bone marrow vacuoles maybe; ‚Äúsmall testis‚Äù no)

* not explained by adverse morphology artifact (e.g., atrophy making ‚Äúsmall‚Äù disappear)

Represent as:

`interface ProtectiveGate {`  
  `minControlIncidence: number;     // default 0.2`  
  `excludedOrganSystems: string[];  // e.g., ["Reproductive"] for some classes`  
  `excludedFindings: string[];      // e.g., ["SMALL"] in testis`  
  `requireDoseResponse?: boolean;`  
`}`

Then protective rules emit:

* either `Protective` with confidence

* or `Trend/Informational` with note: ‚Äúdecrease observed but protective interpretation low-confidence‚Äù

### **3.5 Output requirements (explainability)**

When clinical tier triggers, the surfaced insight should explicitly say *why*:

Example:

* Headline: ‚ÄúTestis atrophy observed (sentinel finding)‚Äù

* Detail:

  * ‚ÄúIncidence: 1/15 at low dose (severity 4)‚Äù

  * ‚ÄúClassified as adverse due to sentinel rule for reproductive atrophy‚Äù

  * ‚ÄúCorroboration: dose-dependent testis weight decrease‚Äù

This is what regulators and tox folks trust: explicit rationale.

### **3.6 Versioning and governance**

You‚Äôll want:

* `clinical_catalog_version`

* `study_profile` (species/strain optional) for tuning thresholds

* changelog to support auditability

---

## **Practical next steps (implementation order)**

1. **Refactor emit contract**: structured `Signal.params` everywhere (unblocks everything else).

2. Implement **FindingKey grouping \+ ownership** (fix Issue \#1).

3. Add **suppression graph** (Issue \#2 stays safe even if surfaced later).

4. Add **SV gates** (Issue \#3) \+ confidence dampeners.

5. Introduce **clinical catalog** (Issue \#4/5) with a tiny v1 set (repro \+ neoplasia \+ neuro \+ marrow).

6. Build the **scoring dashboard** and make it part of CI/regression testing.

